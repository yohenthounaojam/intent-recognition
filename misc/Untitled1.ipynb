{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from src.utils.consts import (HDD_VIDEO_PATH, HDD_ALL_FRAMES_ALL_VIDS_PATH,\n",
    "                         HDD_TRAIN_SIDS, HDD_TEST_SIDS, MAP_LBL_TO_CLS_LYR_0)\n",
    "from src.utils.data_prep_util import extract_frames, get_saved_index_pkl, get_sequence_wise_fvecs_and_labels\n",
    "from src.utils.cnn_lstm_utils import get_cnn_codes_for_frames_tt\n",
    "from src.utils.exp_util import plot_conf_mat_heat_map\n",
    "model = models.resnet18(pretrained=True)\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_id in HDD_TRAIN_SIDS:\n",
    "    frames_fvecs_lst = []\n",
    "    files = os.listdir(HDD_VIDEO_PATH.format(session_id))\n",
    "    all_frames = extract_frames(HDD_VIDEO_PATH.format(session_id)+\"/\"+files[0])\n",
    "    num_frames = all_frames.shape[0]\n",
    "    for start in range(0, num_frames, 40):\n",
    "        end = min(start+40, num_frames)\n",
    "        frames_vecs = get_cnn_codes_for_frames_tt(model, all_frames[start:end])\n",
    "        frames_fvecs_lst.append(frames_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames_fvecs_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 512, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_fvecs_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "frames_lst = []\n",
    "for i in range(3):\n",
    "    print(frames_vecs[i].shape[0])\n",
    "    frames_lst.append(frames_vecs[i].view(512).numpy())\n",
    "    \n",
    "frames_fvecs_lst[0][0].shape\n",
    "len(frames_lst)\n",
    "\n",
    "\n",
    "def get_length(filename):\n",
    "    def get_sec(time_str):\n",
    "        h, m, s = time_str.split(b':')\n",
    "        return int(h) * 3600 + int(m) * 60 + float(s)\n",
    "\n",
    "    result = subprocess.Popen([\"ffprobe\", filename],\n",
    "                              stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    time_string = [x for x in result.stdout.readlines() if b\"Duration\" in x][0]\n",
    "    return get_sec(time_string.split(b\",\")[0].split(b\": \")[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441.034\n"
     ]
    }
   ],
   "source": [
    "for session_id in HDD_TRAIN_SIDS:\n",
    "    files = os.listdir(HDD_VIDEO_PATH.format(session_id))\n",
    "    filename = HDD_VIDEO_PATH.format(session_id)+\"/\"+files[0]\n",
    "    print(get_length(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441.034\n"
     ]
    }
   ],
   "source": [
    "def get_length(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)\n",
    "for session_id in HDD_TRAIN_SIDS:\n",
    "    files = os.listdir(HDD_VIDEO_PATH.format(session_id))\n",
    "    filename = HDD_VIDEO_PATH.format(session_id)+\"/\"+files[0]\n",
    "    print(get_length(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = get_saved_index_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_pd = si[\"events_pd\"]\n",
    "events_pd[\"layer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>event_type</th>\n",
       "      <th>session_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18732</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>201702271123</td>\n",
       "      <td>0</td>\n",
       "      <td>441034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       layer  event_type    session_id  start     end\n",
       "18732      2          32  201702271123      0  441034"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_rows = events_pd[(events_pd[\"session_id\"] == \"201702271123\") & (events_pd[\"layer\"] == 2)]\n",
    "session_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207\n",
      "332.841\n",
      "1208\n",
      "638.991\n",
      "1209\n",
      "1073.961\n",
      "1210\n",
      "1153.347\n",
      "4568\n",
      "167.841\n",
      "4569\n",
      "254.66699999999997\n",
      "4570\n",
      "461.25\n",
      "4571\n",
      "573.207\n",
      "4572\n",
      "713.7239999999999\n",
      "4573\n",
      "805.767\n",
      "4574\n",
      "880.7640000000001\n",
      "4575\n",
      "986.337\n",
      "4576\n",
      "1116.195\n",
      "4577\n",
      "1264.815\n",
      "8953\n",
      "1037.043\n",
      "10839\n",
      "67.71000000000001\n",
      "11857\n",
      "960.261\n",
      "11858\n",
      "1195.3980000000001\n",
      "11859\n",
      "1319.5230000000001\n"
     ]
    }
   ],
   "source": [
    "fps = \"3/1\"\n",
    "for row in session_rows.iterrows():\n",
    "    print(row[0])\n",
    "    print(row[1][\"start\"]/1000 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_prep_util import get_sequence_wise_fvecs_and_labels\n",
    "from src.utils.exp_util import get_map_of_unique_classes_for_layer\n",
    "from src.utils.consts import HDD_TRAIN_SIDS, HDD_TEST_SIDS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120,), (120,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unq_cls, map_lbl_to_cls, map_cls_to_lbl = get_map_of_unique_classes_for_layer(\n",
    "        HDD_TRAIN_SIDS, 0)\n",
    "fvecs, labels = get_sequence_wise_fvecs_and_labels(\"201709210940\", 0, 90, map_lbl_to_cls)\n",
    "fvecs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels[2]))\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 5, 6, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fvecs_t = torch.stack([torch.from_numpy(fvec) for fvec in fvecs[:-1]])\n",
    "labels_t = torch.stack([torch.from_numpy(label) for label in labels[:-1]])\n",
    "print(torch.unique(labels_t))\n",
    "\n",
    "train_data = TensorDataset(fvecs_t, labels_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=40, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 90, 512]) torch.Size([40, 90])\n",
      "torch.Size([40, 90, 512]) torch.Size([40, 90])\n",
      "torch.Size([39, 90, 512]) torch.Size([39, 90])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4, 5.0: 5, 6.0: 6, 7.0: 7, 8.0: 8, 10.0: 9, 11.0: 10, 12.0: 11}\n",
      "{0: 0.0, 1: 1.0, 2: 2.0, 3: 3.0, 4: 4.0, 5: 5.0, 6: 6.0, 7: 7.0, 8: 8.0, 9: 10.0, 10: 11.0, 11: 12.0}\n"
     ]
    }
   ],
   "source": [
    "print(num_unq_cls)\n",
    "print(map_lbl_to_cls)\n",
    "print(map_cls_to_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_ul_cnt, ts_ul_map, ts_cl_map = get_map_of_unique_classes_for_layer(HDD_TEST_SIDS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " {0.0: 0,\n",
       "  1.0: 1,\n",
       "  2.0: 2,\n",
       "  3.0: 3,\n",
       "  4.0: 4,\n",
       "  5.0: 5,\n",
       "  6.0: 6,\n",
       "  7.0: 7,\n",
       "  8.0: 8,\n",
       "  10.0: 9,\n",
       "  11.0: 10,\n",
       "  12.0: 11},\n",
       " {0: 0.0,\n",
       "  1: 1.0,\n",
       "  2: 2.0,\n",
       "  3: 3.0,\n",
       "  4: 4.0,\n",
       "  5: 5.0,\n",
       "  6: 6.0,\n",
       "  7: 7.0,\n",
       "  8: 8.0,\n",
       "  9: 10.0,\n",
       "  10: 11.0,\n",
       "  11: 12.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_ul_cnt, ts_ul_map, ts_cl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 5]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "output = torch.randn(3, 4, 5)\n",
    "train_clss = torch.randn(3, 4)\n",
    "print(output.view(-1, 5).shape, train_clss.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8202, -0.7720,  0.5749,  0.9233, -1.0970],\n",
      "         [-0.4713, -1.2166, -1.8238, -0.7495, -0.3654],\n",
      "         [-1.1689, -0.1251, -1.6567,  0.0965,  1.2511],\n",
      "         [ 2.0249, -0.7272,  0.1559,  1.2814,  0.6847]],\n",
      "\n",
      "        [[ 0.1606, -2.6523,  0.1823,  0.5514, -0.2323],\n",
      "         [ 1.0380, -1.5724,  0.5753,  1.6914, -0.8425],\n",
      "         [ 0.9869,  0.7831, -0.8116, -0.0644, -0.3113],\n",
      "         [ 0.3491, -0.9055, -0.4162, -0.9037, -0.2829]],\n",
      "\n",
      "        [[-0.0191,  0.4710, -0.3959,  2.1329, -0.7635],\n",
      "         [-1.5661,  0.8526,  0.5746, -0.1830,  1.4722],\n",
      "         [-0.8471,  1.1734, -0.9500,  0.9141, -0.1215],\n",
      "         [-0.1937, -1.5870, -0.4267,  1.0605,  0.6665]]])\n",
      "tensor([[-0.8202, -0.7720,  0.5749,  0.9233, -1.0970],\n",
      "        [-0.4713, -1.2166, -1.8238, -0.7495, -0.3654],\n",
      "        [-1.1689, -0.1251, -1.6567,  0.0965,  1.2511],\n",
      "        [ 2.0249, -0.7272,  0.1559,  1.2814,  0.6847],\n",
      "        [ 0.1606, -2.6523,  0.1823,  0.5514, -0.2323],\n",
      "        [ 1.0380, -1.5724,  0.5753,  1.6914, -0.8425],\n",
      "        [ 0.9869,  0.7831, -0.8116, -0.0644, -0.3113],\n",
      "        [ 0.3491, -0.9055, -0.4162, -0.9037, -0.2829],\n",
      "        [-0.0191,  0.4710, -0.3959,  2.1329, -0.7635],\n",
      "        [-1.5661,  0.8526,  0.5746, -0.1830,  1.4722],\n",
      "        [-0.8471,  1.1734, -0.9500,  0.9141, -0.1215],\n",
      "        [-0.1937, -1.5870, -0.4267,  1.0605,  0.6665]])\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(output.view(-1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0      1      2      3      4\n",
      "Actual                                      \n",
      "0          18.68  18.91  21.41  21.87  19.13\n",
      "1          16.07  21.17  19.90  21.94  20.92\n",
      "2          19.54  23.14  18.77  19.28  19.28\n",
      "3          23.78  21.08  20.00  16.76  18.38\n",
      "4          21.46  19.02  18.78  21.22  19.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = np.random.randint(0, 5, 2000)\n",
    "y_pred = np.random.randint(0, 5, 2000)\n",
    "plot_conf_mat_heat_map(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "<class 'generator'>\n",
      "torch.Size([1, 3600, 512]) torch.Size([1, 3600])\n",
      "torch.Size([1, 3600, 512]) torch.Size([1, 3600])\n",
      "torch.Size([1, 2340, 512]) torch.Size([1, 2340])\n",
      "(3,)\n",
      "<class 'generator'>\n",
      "torch.Size([1, 3600, 512]) torch.Size([1, 3600])\n",
      "torch.Size([1, 3600, 512]) torch.Size([1, 3600])\n",
      "torch.Size([1, 2340, 512]) torch.Size([1, 2340])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    fvecs, fclss = get_sequence_wise_fvecs_and_labels(\"201702271017\", 0, 3600, MAP_LBL_TO_CLS_LYR_0)\n",
    "    print(fvecs.shape)\n",
    "    def custom_dl():\n",
    "        for fvec, fcls in zip(fvecs, fclss):\n",
    "            fvec, fcls = torch.from_numpy(fvec).unsqueeze(0), torch.from_numpy(fcls).unsqueeze(0)\n",
    "            #print(fvec.size(), fcls.size())\n",
    "            yield fvec, fcls\n",
    "            \n",
    "    dl = custom_dl()\n",
    "    print(type(dl))\n",
    "    for fvec, fcls in dl:\n",
    "        print(fvec.shape, fcls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3600, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvecs = torch.stack([torch.from_numpy(fvec) for fvec in fvecs[:-1]])\n",
    "fvecs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
