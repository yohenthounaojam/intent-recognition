{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "t:\\HONDAdata\\auto-intention-snns\\misc\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dda4f4679fbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m from ..src.utils.data_prep_util import (extract_frames,\n\u001b[0m\u001b[0;32m     10\u001b[0m                                      get_train_test_tensors_and_labels_lst)\n\u001b[0;32m     11\u001b[0m from ..src.utils.exp_util import (get_layer_and_event_type_df, get_saved_index_pkl, basic_plot, \n",
      "\u001b[1;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "print(os.getcwd())\n",
    "sys.path.append(\".\")\n",
    "import numpy as np\n",
    "from src.utils.data_prep_util import (extract_frames,\n",
    "                                     get_train_test_tensors_and_labels_lst)\n",
    "from src.utils.exp_util import (get_layer_and_event_type_df, get_saved_index_pkl, basic_plot, \n",
    "                                get_epochs_from_session_id_st_en, get_epochs_from_iso_timestamps_lst,\n",
    "                               get_can_bus_corresponding_to_session_id_st_en_dict,\n",
    "                                get_layer_train_test_indices_cls_map_dict,\n",
    "                               get_can_bus_df_from_clipped_dikt_df)\n",
    "from src.utils.consts import (\n",
    "    HDD_SAVED_INDEX_PKL_PATH, HDD_VIDEO_PATH, HDD_DATA_BASE_DIR, HDD_CBUS_CSV_FILES,\n",
    "    HDD_FVECS_PATH)\n",
    "from src.utils.cnn_lstm_utils import get_cnn_codes_for_frames_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict, test_dict, cls_dict = get_layer_train_test_indices_cls_map_dict(0, div_frc=0.8)\n",
    "ffvecs_data = np.load(HDD_FVECS_PATH + \"hdd_frame_vecs_dict_fps_3_1_model_ResNet.npy\", \n",
    "                      allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No feature vector data for index: 2521 found.\n",
      "No feature vector data for index: 2045 found.\n",
      "No feature vector data for index: 3235 found.\n",
      "No feature vector data for index: 2539 found.\n",
      "No feature vector data for index: 2207 found.\n",
      "No feature vector data for index: 4232 found.\n",
      "No feature vector data for index: 4218 found.\n",
      "No feature vector data for index: 4066 found.\n",
      "No feature vector data for index: 4581 found.\n",
      "No feature vector data for index: 4370 found.\n",
      "No feature vector data for index: 5229 found.\n",
      "No feature vector data for index: 5287 found.\n",
      "No feature vector data for index: 2048 found.\n",
      "No feature vector data for index: 2020 found.\n",
      "No feature vector data for index: 2742 found.\n",
      "No feature vector data for index: 4223 found.\n",
      "No feature vector data for index: 3477 found.\n",
      "No feature vector data for index: 5242 found.\n",
      "No feature vector data for index: 2942 found.\n",
      "No feature vector data for index: 7685 found.\n",
      "No feature vector data for index: 7846 found.\n",
      "No feature vector data for index: 9360 found.\n",
      "No feature vector data for index: 7155 found.\n",
      "No feature vector data for index: 8186 found.\n",
      "No feature vector data for index: 10333 found.\n",
      "No feature vector data for index: 10763 found.\n",
      "No feature vector data for index: 9977 found.\n",
      "No feature vector data for index: 10834 found.\n",
      "No feature vector data for index: 10933 found.\n",
      "No feature vector data for index: 10213 found.\n",
      "No feature vector data for index: 10670 found.\n",
      "No feature vector data for index: 10228 found.\n",
      "No feature vector data for index: 10195 found.\n",
      "No feature vector data for index: 10672 found.\n",
      "No feature vector data for index: 9786 found.\n",
      "No feature vector data for index: 9727 found.\n",
      "No feature vector data for index: 10189 found.\n",
      "No feature vector data for index: 10897 found.\n",
      "No feature vector data for index: 10486 found.\n",
      "No feature vector data for index: 10365 found.\n",
      "No feature vector data for index: 10735 found.\n",
      "No feature vector data for index: 9906 found.\n",
      "No feature vector data for index: 10553 found.\n",
      "No feature vector data for index: 9745 found.\n",
      "No feature vector data for index: 10855 found.\n",
      "No feature vector data for index: 11064 found.\n",
      "No feature vector data for index: 10693 found.\n",
      "No feature vector data for index: 10075 found.\n",
      "No feature vector data for index: 11255 found.\n",
      "No feature vector data for index: 9730 found.\n",
      "No feature vector data for index: 11278 found.\n",
      "No feature vector data for index: 11063 found.\n",
      "No feature vector data for index: 10896 found.\n",
      "No feature vector data for index: 10322 found.\n",
      "No feature vector data for index: 10771 found.\n",
      "No feature vector data for index: 10895 found.\n",
      "No feature vector data for index: 10000 found.\n",
      "No feature vector data for index: 11197 found.\n",
      "No feature vector data for index: 10686 found.\n",
      "No feature vector data for index: 10579 found.\n",
      "No feature vector data for index: 10190 found.\n",
      "No feature vector data for index: 9794 found.\n",
      "No feature vector data for index: 10394 found.\n",
      "No feature vector data for index: 10692 found.\n",
      "No feature vector data for index: 10854 found.\n",
      "No feature vector data for index: 10415 found.\n",
      "No feature vector data for index: 10220 found.\n",
      "No feature vector data for index: 10840 found.\n",
      "No feature vector data for index: 11058 found.\n",
      "No feature vector data for index: 10740 found.\n",
      "No feature vector data for index: 720 found.\n",
      "No feature vector data for index: 216 found.\n",
      "No feature vector data for index: 1083 found.\n",
      "No feature vector data for index: 1024 found.\n",
      "No feature vector data for index: 291 found.\n",
      "No feature vector data for index: 201 found.\n",
      "No feature vector data for index: 1303 found.\n",
      "No feature vector data for index: 1218 found.\n",
      "No feature vector data for index: 1217 found.\n",
      "No feature vector data for index: 202 found.\n",
      "No feature vector data for index: 897 found.\n",
      "No feature vector data for index: 381 found.\n",
      "No feature vector data for index: 1227 found.\n",
      "No feature vector data for index: 1196 found.\n",
      "No feature vector data for index: 1363 found.\n",
      "No feature vector data for index: 1037 found.\n",
      "No feature vector data for index: 433 found.\n",
      "No feature vector data for index: 181 found.\n",
      "No feature vector data for index: 1012 found.\n",
      "No feature vector data for index: 838 found.\n",
      "No feature vector data for index: 1499 found.\n",
      "No feature vector data for index: 1226 found.\n",
      "No feature vector data for index: 1268 found.\n",
      "No feature vector data for index: 5939 found.\n",
      "No feature vector data for index: 5446 found.\n",
      "No feature vector data for index: 12550 found.\n",
      "No feature vector data for index: 12583 found.\n",
      "No feature vector data for index: 12557 found.\n",
      "No feature vector data for index: 12544 found.\n",
      "No feature vector data for index: 12590 found.\n",
      "No feature vector data for index: 12624 found.\n",
      "No feature vector data for index: 12600 found.\n",
      "No feature vector data for index: 12567 found.\n",
      "No feature vector data for index: 12609 found.\n",
      "No feature vector data for index: 12593 found.\n",
      "No feature vector data for index: 12549 found.\n",
      "No feature vector data for index: 12561 found.\n",
      "No feature vector data for index: 12572 found.\n",
      "No feature vector data for index: 4098 found.\n",
      "No feature vector data for index: 2821 found.\n",
      "No feature vector data for index: 4979 found.\n",
      "No feature vector data for index: 5092 found.\n",
      "No feature vector data for index: 3361 found.\n",
      "No feature vector data for index: 3484 found.\n",
      "No feature vector data for index: 3616 found.\n",
      "No feature vector data for index: 9247 found.\n",
      "No feature vector data for index: 9411 found.\n",
      "No feature vector data for index: 10571 found.\n",
      "No feature vector data for index: 10583 found.\n",
      "No feature vector data for index: 10587 found.\n",
      "No feature vector data for index: 10697 found.\n",
      "No feature vector data for index: 10701 found.\n",
      "No feature vector data for index: 10724 found.\n",
      "No feature vector data for index: 10764 found.\n",
      "No feature vector data for index: 10770 found.\n",
      "No feature vector data for index: 10782 found.\n",
      "No feature vector data for index: 10835 found.\n",
      "No feature vector data for index: 10927 found.\n",
      "No feature vector data for index: 11065 found.\n",
      "No feature vector data for index: 9619 found.\n",
      "No feature vector data for index: 9624 found.\n",
      "No feature vector data for index: 9721 found.\n",
      "No feature vector data for index: 9803 found.\n",
      "No feature vector data for index: 9973 found.\n",
      "No feature vector data for index: 9987 found.\n",
      "No feature vector data for index: 10039 found.\n",
      "No feature vector data for index: 10181 found.\n",
      "No feature vector data for index: 124 found.\n",
      "No feature vector data for index: 716 found.\n",
      "No feature vector data for index: 769 found.\n",
      "No feature vector data for index: 1065 found.\n",
      "No feature vector data for index: 1131 found.\n",
      "No feature vector data for index: 1436 found.\n",
      "No feature vector data for index: 1475 found.\n",
      "No feature vector data for index: 6562 found.\n",
      "No feature vector data for index: 12574 found.\n",
      "No feature vector data for index: 12575 found.\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, test_data, test_labels = get_train_test_tensors_and_labels_lst(\n",
    "    train_dict, test_dict, ffvecs_data, cls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5167, 2: 1313, 1: 1293, 3: 671, 4: 475, 5: 450, 6: 237, 7: 130, 8: 104, 9: 67, 10: 54})\n",
      "Counter({0: 1289, 2: 328, 1: 315, 3: 168, 4: 119, 5: 112, 6: 60, 7: 33, 8: 27, 9: 17, 10: 15})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "trnl_counter = Counter(train_labels)\n",
    "tstl_counter = Counter(test_labels)\n",
    "print(trnl_counter)\n",
    "print(tstl_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_eq, train_labels_eq, test_data_eq, test_labels_eq = [], [], [], []\n",
    "# def get_balanced_dataset(cls, labels, data, eq_labels, eq_data, label_ctr):\n",
    "#     min_ctr = min(label_ctr[c] for c in range(cls+1))\n",
    "#     ctr = min_ctr\n",
    "#     crnt_cls = labels[0]\n",
    "    \n",
    "#     for i in range(len(labels)):\n",
    "#         if ctr > 0:\n",
    "#             eq_labels.append(labels[i])\n",
    "#             eq_data.append(data[i])\n",
    "#             ctr -= 1\n",
    "#         if labels[i] != crnt_cls and label_ctr[labels[i]] >= min_ctr:\n",
    "#             assert ctr == 0\n",
    "#             crnt_cls = labels[i]\n",
    "#             ctr = min_ctr-1\n",
    "#             eq_labels.append(labels[i])\n",
    "#             eq_data.append(data[i])\n",
    "\n",
    "# get_balanced_dataset(2, train_labels, train_data, train_labels_eq, train_data_eq, trnl_counter)\n",
    "# get_balanced_dataset(2, test_labels, test_data, test_labels_eq, test_data_eq, tstl_counter)\n",
    "# train_data, train_labels, test_data, test_labels = train_data_eq, train_labels_eq, test_data_eq, test_labels_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "basic_plot(train_labels)\n",
    "basic_plot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = get_layer_and_event_type_df(layer=0, event_type=14)\n",
    "# sample_df\n",
    "# saved = get_saved_index_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = saved[\"events_pd\"]\n",
    "# print(df.shape)\n",
    "# k = 0\n",
    "# for index in df.index:\n",
    "#     k+=1\n",
    "# print(k)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "#model = models.resnet18(pretrained=True)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to_tensor = transforms.ToTensor()\n",
    "# # to_tensor also takes care of coverting all the pixel values to range [0, 1].\n",
    "# # Also, Normalize the images with specific mean and std.\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                    std=[0.229, 0.224, 0.225])\n",
    "# model.eval() # Batchnorm and Dropout layers work in eval mode rather training.\n",
    "# # Freeze the parameters as only features are extracted (saves GPU memory too).\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Map the model and data to use GPU if available.\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# saved_idx_pkl = get_saved_index_pkl()\n",
    "# # df = saved_idx_pkl[\"events_pd\"]\n",
    "# # index_g15 = []\n",
    "# # for i in df.index:\n",
    "# #     if (df.loc[i][\"end\"] - df.loc[i][\"start\"])/1000 > 15:\n",
    "# #         index_g15.append((i, df.loc[i][\"event_type\"]))\n",
    "# # frame_vecs_dict = {}\n",
    "# #feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.loc[123][\"end\"] - df.loc[123][\"start\"])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(saved_idx_pkl.keys())\n",
    "# print(saved_idx_pkl[\"layer_ix\"])\n",
    "# print(\"$\"*50)\n",
    "# print(saved_idx_pkl[\"event_type_ix\"])\n",
    "# print(index_g15)  # Indices and eventypes with clip time > 15secs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with torch.no_grad():\n",
    "#     for index in df.index[:20]:\n",
    "#         row = df.loc[index]\n",
    "#         layer, event_type, session_id, start, end = (row[\"layer\"],\n",
    "#             row[\"event_type\"], row[\"session_id\"], row[\"start\"], row[\"end\"])\n",
    "#         files = os.listdir(HDD_VIDEO_PATH.format(session_id))\n",
    "#         frames = extract_frames(\n",
    "#             HDD_VIDEO_PATH.format(session_id)+\"/\"+files[0], start/1000, end/1000,\n",
    "#             \"3/1\")\n",
    "#         print(\"Frame extracted\")\n",
    "#         frames_tensor = torch.stack([normalize(to_tensor(frame)) for frame in frames])\n",
    "#         # Image dim 299 for inception_v3 model and 224 for rest of the models.\n",
    "#         assert frames_tensor.shape[2] >= 299\n",
    "#         assert frames_tensor.shape[3] >= 299\n",
    "    \n",
    "#         frames_tensor = frames_tensor.cuda()\n",
    "#         print(frames_tensor.requires_grad)\n",
    "#         print(\"Mapped to Cuda\")\n",
    "#         ff_vecs = feature_extractor(frames_tensor)\n",
    "#         ff_vecs = ff_vecs.to(\"cpu\")\n",
    "#         print(\"Features extracted\", ff_vecs.device)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         del frames_tensor\n",
    "#         frame_vecs_dict[index] = (\n",
    "#             ff_vecs.reshape(1, ff_vecs.shape[0], ff_vecs.shape[1]),\n",
    "#             (layer, event_type))\n",
    "        \n",
    "#         print(\"%s Done!\" % index)\n",
    "    \n",
    "# np.save(HDD_FVECS_PATH + \"hdd_frame_vecs_dict.npy\", frame_vecs_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(1): # sample_df.shape[0]):\n",
    "#     session_id, start, end = sample_df.iloc[i].session_id, sample_df.iloc[i].start, sample_df.iloc[i].end\n",
    "#     #print(session_id, start, end)\n",
    "#     files = os.listdir(HDD_VIDEO_PATH.format(session_id))\n",
    "#     if len(files) != 1:\n",
    "#         print(\"Missing some videos.\")\n",
    "#     #print(files[0])\n",
    "#     path = HDD_VIDEO_PATH.format(session_id)+\"/\"+files[0]\n",
    "#     #print(path)\n",
    "#     frames = extract_frames(path, start/1000, end/1000, \"2/1\")\n",
    "# frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frame_vecs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frame_vecs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# out = get_cnn_codes_for_frames_tt(model, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(out.shape)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# out = out.reshape(1, out.shape[0], 1024)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.cnn_lstm_utils import LSTMVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMVR(\n",
       "  (_lstm): LSTM(512, 1024, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (_dptlyr): Dropout(p=0.2, inplace=False)\n",
       "  (_lfc): Linear(in_features=1024, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, hidden_dim, num_layers, num_clss, dropout = 512, 1024, 2, 11, 0.2\n",
    "lr = 0.0002\n",
    "lstm_model = LSTMVR(input_dim, hidden_dim, num_layers, num_clss, dropout)\n",
    "lstm_model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)\n",
    "lstm_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5052404403686523\n",
      "0.62465500831604\n",
      "0.4850667715072632\n",
      "1.5445948839187622\n",
      "2.022507667541504\n",
      "0.9785845279693604\n",
      "0.7031291723251343\n",
      "1.0962022542953491\n",
      "2.760429859161377\n",
      "0.8786996603012085\n",
      "0 Epoch Done\n",
      "1.6653443574905396\n",
      "0.3144099712371826\n",
      "0.7114413976669312\n",
      "0.895331621170044\n",
      "0.7945927381515503\n",
      "0.6980631351470947\n",
      "1.6742186546325684\n",
      "0.08749079704284668\n",
      "0.6098208427429199\n",
      "0.8381286859512329\n",
      "1 Epoch Done\n",
      "0.4096717834472656\n",
      "2.5635764598846436\n",
      "0.6916341781616211\n",
      "0.8153316974639893\n",
      "0.1371932029724121\n",
      "0.46544313430786133\n",
      "0.011321783065795898\n",
      "1.1334939002990723\n",
      "0.2188267707824707\n",
      "0.7511714100837708\n",
      "2 Epoch Done\n",
      "1.896531581878662\n",
      "0.4949069023132324\n",
      "0.2511790990829468\n",
      "1.170271635055542\n",
      "1.0201406478881836\n",
      "0.4609870910644531\n",
      "0.21937894821166992\n",
      "0.011166810989379883\n",
      "0.10050249099731445\n",
      "1.3019628524780273\n",
      "3 Epoch Done\n",
      "0.049329280853271484\n",
      "0.9283527135848999\n",
      "0.638721227645874\n",
      "0.017502546310424805\n",
      "0.5086121559143066\n",
      "0.3108122944831848\n",
      "0.3717426061630249\n",
      "2.9521498680114746\n",
      "0.002514362335205078\n",
      "0.0013642311096191406\n",
      "4 Epoch Done\n",
      "0.4283885955810547\n",
      "0.7116363048553467\n",
      "0.00887918472290039\n",
      "2.209461212158203\n",
      "0.8322923183441162\n",
      "0.6918517351150513\n",
      "0.07206487655639648\n",
      "0.01759958267211914\n",
      "0.14233875274658203\n",
      "0.0015194416046142578\n",
      "5 Epoch Done\n",
      "0.1569480299949646\n",
      "0.05627870559692383\n",
      "0.35966038703918457\n",
      "1.3576005697250366\n",
      "0.0021584033966064453\n",
      "0.03172874450683594\n",
      "0.26786160469055176\n",
      "0.937048077583313\n",
      "5.00431489944458\n",
      "0.3696151375770569\n",
      "6 Epoch Done\n",
      "0.4975273609161377\n",
      "0.3899874985218048\n",
      "0.7272121906280518\n",
      "0.002196073532104492\n",
      "0.002202272415161133\n",
      "0.056117236614227295\n",
      "1.0177106857299805\n",
      "0.01096808910369873\n",
      "0.26740288734436035\n",
      "2.95767879486084\n",
      "7 Epoch Done\n",
      "0.8842816948890686\n",
      "1.2716954946517944\n",
      "1.5781983137130737\n",
      "0.9893951416015625\n",
      "0.028470158576965332\n",
      "0.0016921758651733398\n",
      "0.6801179647445679\n",
      "0.0007085800170898438\n",
      "0.20296990871429443\n",
      "0.24465236067771912\n",
      "8 Epoch Done\n",
      "0.08888936042785645\n",
      "0.2574600875377655\n",
      "0.0051424503326416016\n",
      "0.3320620656013489\n",
      "0.1271735429763794\n",
      "2.212052822113037\n",
      "3.4963760375976562\n",
      "0.2261359691619873\n",
      "0.02918742597103119\n",
      "0.002097010612487793\n",
      "9 Epoch Done\n",
      "0.0005970001220703125\n",
      "0.13467562198638916\n",
      "1.0942984819412231\n",
      "0.024431586265563965\n",
      "0.0847574770450592\n",
      "0.32007527351379395\n",
      "1.7165089845657349\n",
      "0.039559245109558105\n",
      "0.22577525675296783\n",
      "0.1382979154586792\n",
      "10 Epoch Done\n",
      "0.1436673402786255\n",
      "0.0010950565338134766\n",
      "0.10359732806682587\n",
      "0.2651839256286621\n",
      "8.630752563476562e-05\n",
      "0.44369763135910034\n",
      "1.7702271938323975\n",
      "0.0027041807770729065\n",
      "0.14589738845825195\n",
      "0.27466294169425964\n",
      "11 Epoch Done\n",
      "0.029324233531951904\n",
      "0.1909545660018921\n",
      "0.06784896552562714\n",
      "0.05203413963317871\n",
      "0.0473998486995697\n",
      "0.12876534461975098\n",
      "0.005893230438232422\n",
      "3.1084275245666504\n",
      "0.09624090790748596\n",
      "0.014754533767700195\n",
      "12 Epoch Done\n",
      "0.35367584228515625\n",
      "5.8531761169433594e-05\n",
      "1.76583731174469\n",
      "0.19587835669517517\n",
      "0.0003868788480758667\n",
      "7.176399230957031e-05\n",
      "2.666426181793213\n",
      "0.40001216530799866\n",
      "0.39701586961746216\n",
      "0.13428550958633423\n",
      "13 Epoch Done\n",
      "0.11721035838127136\n",
      "0.0023602843284606934\n",
      "0.03224658966064453\n",
      "0.13553011417388916\n",
      "0.11069878935813904\n",
      "0.0010163187980651855\n",
      "1.4132071733474731\n",
      "0.6092305183410645\n",
      "1.6933889389038086\n",
      "0.20322871208190918\n",
      "14 Epoch Done\n",
      "6.01725435256958\n",
      "0.08673238754272461\n",
      "1.800060272216797e-05\n",
      "0.0038590431213378906\n",
      "0.07372808456420898\n",
      "0.241363525390625\n",
      "3.4426708221435547\n",
      "0.026123762130737305\n",
      "0.000652313232421875\n",
      "0.001619577407836914\n",
      "15 Epoch Done\n",
      "0.00333249568939209\n",
      "1.8855178356170654\n",
      "0.06151461601257324\n",
      "9.453296661376953e-05\n",
      "0.11285269260406494\n",
      "0.040199995040893555\n",
      "0.11581569910049438\n",
      "0.011815309524536133\n",
      "0.7800000905990601\n",
      "0.0017633438110351562\n",
      "16 Epoch Done\n",
      "0.08371955156326294\n",
      "0.562779426574707\n",
      "4.410743713378906e-06\n",
      "0.00970757007598877\n",
      "9.02414321899414e-05\n",
      "0.023716449737548828\n",
      "0.025673002004623413\n",
      "0.05569446086883545\n",
      "0.018909931182861328\n",
      "1.381260871887207\n",
      "17 Epoch Done\n",
      "0.005254030227661133\n",
      "0.0004546642303466797\n",
      "0.005197882652282715\n",
      "0.005929470062255859\n",
      "0.025889217853546143\n",
      "0.03816366195678711\n",
      "0.03859132528305054\n",
      "0.030111968517303467\n",
      "2.3012032508850098\n",
      "7.867813110351562e-05\n",
      "18 Epoch Done\n",
      "0.00010466575622558594\n",
      "7.724761962890625e-05\n",
      "0.0321345329284668\n",
      "1.4248816967010498\n",
      "0.0012416839599609375\n",
      "0.15450632572174072\n",
      "0.003585338592529297\n",
      "0.04108297824859619\n",
      "0.012360811233520508\n",
      "0.0018627643585205078\n",
      "19 Epoch Done\n",
      "1.5497207641601562e-06\n",
      "0.17668282985687256\n",
      "0.0001575946807861328\n",
      "0.0003688335418701172\n",
      "0.43783092498779297\n",
      "8.45193862915039e-05\n",
      "2.248012065887451\n",
      "0.01197141408920288\n",
      "2.555898666381836\n",
      "0.0031931400299072266\n",
      "20 Epoch Done\n",
      "3.9696693420410156e-05\n",
      "0.03662395477294922\n",
      "0.004681229591369629\n",
      "0.007618904113769531\n",
      "1.2159347534179688e-05\n",
      "0.06464898586273193\n",
      "0.0001366138458251953\n",
      "0.9306380748748779\n",
      "0.0011601448059082031\n",
      "0.12499666213989258\n",
      "21 Epoch Done\n",
      "0.006007194519042969\n",
      "9.107589721679688e-05\n",
      "1.049041748046875e-05\n",
      "0.2930338382720947\n",
      "0.0034852027893066406\n",
      "0.002556920051574707\n",
      "6.151199340820312e-05\n",
      "0.0011208057403564453\n",
      "1.5142221450805664\n",
      "1.1008243560791016\n",
      "22 Epoch Done\n",
      "0.01995253562927246\n",
      "0.0009262561798095703\n",
      "0.10899806022644043\n",
      "2.4318695068359375e-05\n",
      "0.0002505779266357422\n",
      "0.028595566749572754\n",
      "0.700350284576416\n",
      "0.005615234375\n",
      "0.1951122283935547\n",
      "5.221366882324219e-05\n",
      "23 Epoch Done\n",
      "0.9085896015167236\n",
      "0.11304068565368652\n",
      "5.626678466796875e-05\n",
      "5.054473876953125e-05\n",
      "0.00012874603271484375\n",
      "0.38532930612564087\n",
      "8.58306884765625e-05\n",
      "0.0010814666748046875\n",
      "0.022392749786376953\n",
      "3.5762786865234375e-06\n",
      "24 Epoch Done\n",
      "0.0031299591064453125\n",
      "2.566056728363037\n",
      "4.76837158203125e-07\n",
      "1.7404556274414062e-05\n",
      "2.384185791015625e-05\n",
      "1.0013580322265625e-05\n",
      "0.028107523918151855\n",
      "0.00036525726318359375\n",
      "0.0001537799835205078\n",
      "6.246566772460938e-05\n",
      "25 Epoch Done\n",
      "0.018057584762573242\n",
      "8.821487426757812e-06\n",
      "0.1084592342376709\n",
      "0.024387598037719727\n",
      "0.00020122528076171875\n",
      "3.337860107421875e-05\n",
      "8.058547973632812e-05\n",
      "2.963007688522339\n",
      "0.06081819534301758\n",
      "1.9073486328125e-06\n",
      "26 Epoch Done\n",
      "1.71661376953125e-05\n",
      "0.004124641418457031\n",
      "2.982470989227295\n",
      "0.0040435791015625\n",
      "4.76837158203125e-07\n",
      "2.9802322387695312e-05\n",
      "9.5367431640625e-07\n",
      "7.104873657226562e-05\n",
      "0.04206705093383789\n",
      "0.005823373794555664\n",
      "27 Epoch Done\n",
      "2.1042404174804688\n",
      "0.0002162456512451172\n",
      "0.0034524202346801758\n",
      "4.291534423828125e-06\n",
      "0.018035411834716797\n",
      "6.103515625e-05\n",
      "0.026376962661743164\n",
      "0.07798027992248535\n",
      "0.005309104919433594\n",
      "0.00022172927856445312\n",
      "28 Epoch Done\n",
      "0.2027578353881836\n",
      "4.76837158203125e-07\n",
      "4.76837158203125e-07\n",
      "0.05442523956298828\n",
      "0.01675593852996826\n",
      "5.3882598876953125e-05\n",
      "0.001936197280883789\n",
      "0.008862972259521484\n",
      "0.0012025833129882812\n",
      "0.0038946866989135742\n",
      "29 Epoch Done\n",
      "0.005951404571533203\n",
      "3.910064697265625e-05\n",
      "0.041239261627197266\n",
      "0.0\n",
      "0.004376476630568504\n",
      "0.008692622184753418\n",
      "5.1975250244140625e-05\n",
      "3.7670135498046875e-05\n",
      "0.02379775047302246\n",
      "0.0020041465759277344\n",
      "30 Epoch Done\n",
      "0.0\n",
      "1.8358230590820312e-05\n",
      "0.09301042556762695\n",
      "9.250640869140625e-05\n",
      "0.030232906341552734\n",
      "0.003510713577270508\n",
      "4.291534423828125e-06\n",
      "0.0019507408142089844\n",
      "0.0008161067962646484\n",
      "0.011861801147460938\n",
      "31 Epoch Done\n",
      "0.0005154609680175781\n",
      "1.838674545288086\n",
      "2.1457672119140625e-05\n",
      "0.04428410530090332\n",
      "0.004569530487060547\n",
      "0.20759975910186768\n",
      "0.0\n",
      "0.0012928247451782227\n",
      "0.004509925842285156\n",
      "0.0013530254364013672\n",
      "32 Epoch Done\n",
      "0.0047817230224609375\n",
      "0.06117439270019531\n",
      "0.002490401268005371\n",
      "7.152557373046875e-05\n",
      "0.09240961074829102\n",
      "4.76837158203125e-07\n",
      "0.02614593505859375\n",
      "2.86102294921875e-05\n",
      "0.00038188695907592773\n",
      "0.0026183128356933594\n",
      "33 Epoch Done\n",
      "0.002712726593017578\n",
      "2.86102294921875e-06\n",
      "0.0\n",
      "0.12295234203338623\n",
      "0.00019299983978271484\n",
      "3.9577484130859375e-05\n",
      "1.0868425369262695\n",
      "0.00012183189392089844\n",
      "0.031227588653564453\n",
      "9.393692016601562e-05\n",
      "34 Epoch Done\n",
      "0.0009953975677490234\n",
      "0.0375370979309082\n",
      "0.06294584274291992\n",
      "2.8133392333984375e-05\n",
      "1.9073486328125e-06\n",
      "0.0\n",
      "0.0001201629638671875\n",
      "1.5807185173034668\n",
      "3.337860107421875e-06\n",
      "0.0006647109985351562\n",
      "35 Epoch Done\n",
      "0.0038919448852539062\n",
      "9.5367431640625e-07\n",
      "0.0003113746643066406\n",
      "0.0021994709968566895\n",
      "0.0\n",
      "0.00010228157043457031\n",
      "4.76837158203125e-07\n",
      "6.198883056640625e-06\n",
      "0.14465880393981934\n",
      "1.4399211406707764\n",
      "36 Epoch Done\n",
      "8.296966552734375e-05\n",
      "0.0\n",
      "0.5310368537902832\n",
      "0.00014495849609375\n",
      "0.0002989768981933594\n",
      "0.014070510864257812\n",
      "0.000904083251953125\n",
      "2.384185791015625e-06\n",
      "0.00029850006103515625\n",
      "7.152557373046875e-06\n",
      "37 Epoch Done\n",
      "0.18441104888916016\n",
      "8.106231689453125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.777576446533203e-05\n",
      "0.003910161554813385\n",
      "2.86102294921875e-06\n",
      "7.62939453125e-06\n",
      "1.5497207641601562e-05\n",
      "0.0\n",
      "7.534027099609375e-05\n",
      "0.012479543685913086\n",
      "38 Epoch Done\n",
      "2.09808349609375e-05\n",
      "3.421306610107422e-05\n",
      "0.0017468929290771484\n",
      "0.004300117492675781\n",
      "1.1920928955078125e-05\n",
      "2.86102294921875e-06\n",
      "0.19797754287719727\n",
      "0.0\n",
      "7.152557373046875e-07\n",
      "0.002781391143798828\n",
      "39 Epoch Done\n",
      "0.0003268718719482422\n",
      "4.76837158203125e-06\n",
      "0.08720207214355469\n",
      "0.1892690658569336\n",
      "0.00045299530029296875\n",
      "0.014460563659667969\n",
      "3.2901763916015625e-05\n",
      "3.814697265625e-06\n",
      "0.0\n",
      "0.00034737586975097656\n",
      "40 Epoch Done\n",
      "0.9531698226928711\n",
      "4.029273986816406e-05\n",
      "4.291534423828125e-06\n",
      "0.0\n",
      "0.06350231170654297\n",
      "0.0\n",
      "0.2510294020175934\n",
      "0.052631497383117676\n",
      "0.018322229385375977\n",
      "0.00010013580322265625\n",
      "41 Epoch Done\n",
      "0.0\n",
      "0.5997343063354492\n",
      "0.0\n",
      "0.005520343780517578\n",
      "0.003791213035583496\n",
      "0.008625030517578125\n",
      "0.0005353689193725586\n",
      "0.03952217102050781\n",
      "1.239776611328125e-05\n",
      "0.0\n",
      "42 Epoch Done\n",
      "3.5762786865234375e-07\n",
      "3.814697265625e-06\n",
      "0.0010607242584228516\n",
      "0.0\n",
      "1.9073486328125e-06\n",
      "0.03773641586303711\n",
      "0.0\n",
      "0.010719001293182373\n",
      "0.0008831024169921875\n",
      "0.005865573883056641\n",
      "43 Epoch Done\n",
      "1.52587890625e-05\n",
      "0.02433013916015625\n",
      "9.5367431640625e-07\n",
      "0.3597078323364258\n",
      "0.00013685226440429688\n",
      "0.012232780456542969\n",
      "0.00020813941955566406\n",
      "0.0\n",
      "2.384185791015625e-07\n",
      "0.0\n",
      "44 Epoch Done\n",
      "4.1961669921875e-05\n",
      "0.10092830657958984\n",
      "0.048159122467041016\n",
      "0.0\n",
      "1.6689300537109375e-05\n",
      "0.0\n",
      "0.004172086715698242\n",
      "0.0033245086669921875\n",
      "6.890296936035156e-05\n",
      "0.00015354156494140625\n",
      "45 Epoch Done\n",
      "0.004056692123413086\n",
      "1.9073486328125e-06\n",
      "0.05154705047607422\n",
      "9.632110595703125e-05\n",
      "2.384185791015625e-05\n",
      "0.0012722015380859375\n",
      "1.6570091247558594e-05\n",
      "0.0\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "46 Epoch Done\n",
      "3.528594970703125e-05\n",
      "5.91278076171875e-05\n",
      "0.10731399059295654\n",
      "5.7220458984375e-06\n",
      "0.0005397796630859375\n",
      "3.814697265625e-06\n",
      "0.0025589466094970703\n",
      "0.39409828186035156\n",
      "9.5367431640625e-07\n",
      "1.71661376953125e-05\n",
      "47 Epoch Done\n",
      "1.8596649169921875e-05\n",
      "1.9073486328125e-06\n",
      "0.0\n",
      "0.16215085983276367\n",
      "0.0006535053253173828\n",
      "9.5367431640625e-07\n",
      "4.0531158447265625e-05\n",
      "0.006549835205078125\n",
      "6.389617919921875e-05\n",
      "0.01082611083984375\n",
      "48 Epoch Done\n",
      "0.29479122161865234\n",
      "1.71661376953125e-05\n",
      "0.016611099243164062\n",
      "8.58306884765625e-06\n",
      "0.0012581348419189453\n",
      "0.0\n",
      "0.0\n",
      "0.03124856948852539\n",
      "0.00034332275390625\n",
      "0.0030172765254974365\n",
      "49 Epoch Done\n"
     ]
    }
   ],
   "source": [
    "#al = torch.Tensor([0]).long().to(device)\n",
    "import random\n",
    "\n",
    "for ep in range(50):\n",
    "    indices = np.arange(len(train_data)).tolist()\n",
    "    indices = random.sample(indices, len(indices))\n",
    "    for i in indices:\n",
    "        optimizer.zero_grad()\n",
    "        output = lstm_model(train_data[i].to(device).requires_grad_())\n",
    "        loss = criterion(output, torch.Tensor([train_labels[i]]).long().to(device))\n",
    "        if i%1000 == 0:\n",
    "            print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"%s Epoch Done\" % ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4631494160289972\n"
     ]
    }
   ],
   "source": [
    "lstm_model.eval()\n",
    "indices = np.arange(len(test_data)).tolist()\n",
    "indices = random.sample(indices, len(indices))\n",
    "acc = 0\n",
    "out_labels = []\n",
    "for i in indices:\n",
    "    output = lstm_model(test_data[i].to(device))\n",
    "    output = torch.max(output.data, 1)[1]\n",
    "    if output == test_labels[i] and output == 0:\n",
    "        acc += 1\n",
    "    out_labels.append((i, output))\n",
    "print(acc/len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "cls_dict\n",
    "cnt = 0\n",
    "for i in range(len(test_labels)):\n",
    "    if out_labels[i][1] == 11:\n",
    "         cnt += 1\n",
    "print(cnt/len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5\n",
    "# nb_classes = 2\n",
    "# in_features = 10\n",
    "\n",
    "# model = nn.Linear(in_features, nb_classes)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# x = torch.randn(batch_size, in_features)\n",
    "# target = torch.empty(batch_size, dtype=torch.long).random_(nb_classes)\n",
    "\n",
    "# output = model(x)\n",
    "# loss = criterion(output, target)\n",
    "# loss.backward()\n",
    "# print(output)\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "\n",
    "# #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# class MyInceptionFeatureExtractor(nn.Module):\n",
    "#     def __init__(self, inception, transform_input=False):\n",
    "#         super(MyInceptionFeatureExtractor, self).__init__()\n",
    "#         self.transform_input = transform_input\n",
    "#         self.Conv2d_1a_3x3 = inception.Conv2d_1a_3x3\n",
    "#         self.Conv2d_2a_3x3 = inception.Conv2d_2a_3x3\n",
    "#         self.Conv2d_2b_3x3 = inception.Conv2d_2b_3x3\n",
    "#         self.Conv2d_3b_1x1 = inception.Conv2d_3b_1x1\n",
    "#         self.Conv2d_4a_3x3 = inception.Conv2d_4a_3x3\n",
    "#         self.Mixed_5b = inception.Mixed_5b\n",
    "#         # stop where you want, copy paste from the model def\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.transform_input:\n",
    "#             x = x.clone()\n",
    "#             x[0] = x[0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "#             x[1] = x[1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "#             x[2] = x[2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "#         # 299 x 299 x 3\n",
    "#         x = self.Conv2d_1a_3x3(x)\n",
    "#         # 149 x 149 x 32\n",
    "#         x = self.Conv2d_2a_3x3(x)\n",
    "#         # 147 x 147 x 32\n",
    "#         x = self.Conv2d_2b_3x3(x)\n",
    "#         # 147 x 147 x 64\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "#         # 73 x 73 x 64\n",
    "#         x = self.Conv2d_3b_1x1(x)\n",
    "#         # 73 x 73 x 80\n",
    "#         x = self.Conv2d_4a_3x3(x)\n",
    "#         # 71 x 71 x 192\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "#         # 35 x 35 x 192\n",
    "#         x = self.Mixed_5b(x)\n",
    "#         # copy paste from model definition, just stopping where you want\n",
    "#         return x\n",
    "\n",
    "# inception = torchvision.models.inception_v3(pretrained=True)\n",
    "# my_inception = MyInceptionFeatureExtractor(inception)\n",
    "# #my_inception.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python_defaultSpec_1594844495733"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}